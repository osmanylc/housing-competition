{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import cleaning as cl\n",
    "import tuning as tn\n",
    "\n",
    "seed = 1337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffd2d8a76a618d9b5e78773072cdfdb8def4aa74"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "X_eval = pd.read_csv('test.csv')\n",
    "\n",
    "X = train_df.drop(columns='SalePrice')\n",
    "y = train_df.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up data for model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, X_eval = cl.create_one_hot_encoding(X, y, X_eval)\n",
    "# X_t, X_v, y_t, y_v = train_test_split(X, y, \n",
    "#                                       test_size=.2,\n",
    "#                                       random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "models = {'rfr': RandomForestRegressor(n_estimators=100, \n",
    "                                       criterion='mae', \n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=seed),\n",
    "          'xgbr': XGBRegressor(n_estimators=100,\n",
    "                               random_state=seed), \n",
    "          'skgbr': GradientBoostingRegressor(loss='lad', \n",
    "                                             n_estimators=100,\n",
    "                                             random_state=seed)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline models into estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "estimators = {name: make_pipeline(SimpleImputer(), model) \n",
    "              for name, model in models.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit estimators to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {'rfr': {},\n",
    "              'xgbr': {'xgbregressor__eval_set': [(X_v.values, y_v.values)],\n",
    "                       'xgbregressor__eval_metric': 'mae',\n",
    "                       'xgbregressor__early_stopping_rounds': 100,\n",
    "                       'xgbregressor__verbose': False}, \n",
    "              'skgbr': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, params in fit_params.items():\n",
    "    estimators[name].fit(X_t, y_t, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "for name, estimator in estimators.items():\n",
    "    y_pred = estimator.predict(X_v)\n",
    "\n",
    "    print(mean_absolute_error(y_pred, y_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cross validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = {}\n",
    "\n",
    "for name, estimator in estimators.items():\n",
    "    cv_scores[name] = cross_val_score(estimator, X, y, cv=5,\n",
    "                                      scoring='neg_mean_absolute_error', fit_params=fit_params[name])\n",
    "    \n",
    "    print(f'{name} cv score: {-np.mean(cv_scores[name])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cv for hyperparameter tuning: XGBR\n",
    "\n",
    "Let's try to choose the optimal value for:\n",
    "\n",
    "1. `n_estimators`\n",
    "2. `learning_rate`\n",
    "\n",
    "TODO: Automate hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_est_set = np.random.randint(600, 1000, 10)\n",
    "lr_set = np.random.uniform(.03, .06, 10)\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for n_est, lr in zip(n_est_set, lr_set):\n",
    "    cachedir = mkdtemp()\n",
    "    xgbr = make_pipeline(SimpleImputer(), \n",
    "                         XGBRegressor(n_estimators=n_est, learning_rate=lr, random_state=seed),\n",
    "                         memory=cachedir)\n",
    "    cv_score = cross_val_score(xgbr, X, y, cv=5,\n",
    "                               scoring='neg_mean_absolute_error')\n",
    "    cv_scores.append({'cv_score': -np.mean(cv_score), 'n_est': n_est, 'lr': lr})\n",
    "    print(cv_scores[-1])\n",
    "\n",
    "rmtree(cachedir)\n",
    "    \n",
    "min(cv_scores, key=lambda x: x['cv_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "\n",
    "def pick_n_est_lr(n_est_range, lr_range, n):\n",
    "    n_est_set = np.random.randint(*n_est_range, n)\n",
    "    lr_set = np.random.uniform(*lr_range, n)\n",
    "    \n",
    "    cv_score = []\n",
    "    \n",
    "    cachedir = mkdtemp()\n",
    "    for n_est, lr in zip(n_est_set, lr_set):\n",
    "        xgbr = make_pipeline(SimpleImputer(), \n",
    "                             XGBRegressor(n_estimators=n_est, learning_rate=lr, random_state=seed),\n",
    "                             memory=cachedir)\n",
    "        cv_score = cross_val_score(xgbr, X, y, cv=5,\n",
    "                                   scoring='neg_mean_absolute_error')\n",
    "        cv_scores.append({'cv_score': -np.mean(cv_score), 'n_est': n_est, 'lr': lr})\n",
    "    rmtree(cachedir)\n",
    "    \n",
    "    return min(cv_scores, key=lambda x: x['cv_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = tn.pick_xgbr_hyperparams(X, y, (100, 1000), (.1, .2), 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = (make_pipeline(SimpleImputer(),\n",
    "                             XGBRegressor(n_estimators=842, learning_rate=.05377, random_state=seed))\n",
    "               .fit(X,y)\n",
    "               .predict(X_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({'Id': X_eval.Id.astype(int), 'SalePrice': y_pred_test})\n",
    "out.to_csv('xgbr_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make partial dependence plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgbt = GradientBoostingRegressor(n_estimators=300, loss='lad')\n",
    "bgbt.fit(X_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = ['LotArea', 'BedroomAbvGr', 'OverallCond', 'TotRmsAbvGrd']\n",
    "features_indices = [X_t.columns.get_loc(f) for f in important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_dependence(bgbt, X_t, [0,1], important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_dependence(bgbt, X_t, [2,3], important_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
